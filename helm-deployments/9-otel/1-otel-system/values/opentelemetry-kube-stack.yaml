opentelemetry-kube-stack:
  enabled: true
  fullnameOverride: otel-kube-stack
  # Enables a cleanup job to make sure the CRs are uninstalled before the operator
  cleanupJob:
    enabled: true
  crds:
    install: true

  # Top level field related to the OpenTelemetry Operator
  opentelemetry-operator:
    # Field indicating whether the operator is enabled or not
    enabled: false
    crds:
      create: false

  # This is the default configuration for all collectors generated by the chart.
  # Any collectors in the `collectors` are overlayed on top of this configuration.
  defaultCRConfig:
    enabled: false
  # Each collector configuration is layered on top of the `defaultCRConfig`, overriding a default if set.
  # This configuration allows for multiple layers of overrides for different clusters. For example, you could
  # create a collector called test with an OTLP exporter in your values.yaml, and then override the endpoint's
  # destination in a file called values-staging.yaml.
  collectors:
    daemon:
      suffix: daemon
      mode: daemonset
      enabled: true
      # A scrape config file to instruct the daemon collector to pull metrics from any matching targets on the same node with
      # prometheus.io/scrape=true
      # This config also scrapes a running node exporter and the kubelet CAdvisor metrics which aren't currently supported.
      scrape_configs_file: "daemon_scrape_configs.yaml"
      presets:
        logsCollection:
          enabled: false
        kubeletMetrics:
          enabled: false
        hostMetrics:
          enabled: false
        kubernetesAttributes:
          enabled: false
    cluster:
      suffix: cluster-stats
      replicas: 1
      mode: deployment
      enabled: false
      presets:
        kubernetesAttributes:
          enabled: true
        kubernetesEvents:
          enabled: true
        clusterMetrics:
          enabled: true
      config:
        receivers: {}
        processors:
          batch:
            send_batch_size: 1000
            timeout: 1s
            send_batch_max_size: 1500
          resourcedetection/env:
            detectors: [env]
            timeout: 2s
            override: false
        exporters:
          debug: {}
        service:
          pipelines:
            metrics:
              receivers: [k8s_cluster]
              processors: [resourcedetection/env, batch]
              exporters: [debug]
            logs:
              receivers: [k8sobjects]
              processors: [resourcedetection/env, batch]
              exporters: [debug]


  # Instrumentation configuration
  instrumentation:
    # Whether instrumentation is enabled or not
    enabled: false
    labels: {}
    annotations: {}

    # Exporter configuration
    exporter:
      # This is the default collector's service
      # Upon creation of a tracing collector, edit this endpoint.
      endpoint: http://collector-collector:4317

    # Resource configuration
    resource:
      # environment: dev
      addK8sUIDAttributes: true

    # Propagators configuration
    propagators:
      - tracecontext
      - baggage
      - b3
      - b3multi
      - jaeger
      - xray
      - ottrace

    # Sampler configuration
    sampler: {}
  kubernetesServiceMonitors:
    enabled: false
    ignoreNamespaceSelectors: false
  kubeApiServer:
    enabled: false
  ## Component scraping the kubelet and kubelet-hosted cAdvisor
  ## the configuration for this is currently only in kubelet_scrape_configs.yaml
  ## This is because kubelet doesn't have a service and can only be scraped manually.
  kubelet:
    enabled: false
    namespace: kube-system
  ## Component scraping the kube controller manager
  ##
  kubeControllerManager:
    enabled: false
    service:
      enabled: false
    serviceMonitor:
      enabled: false
  ## Component scraping coreDns. Use either this or kubeDns
  ##
  coreDns:
    enabled: false
    service:
      enabled: true
      port: 9153
      targetPort: 9153
    serviceMonitor:
      enabled: false
  kubeDns:
    enabled: false
    service:
      dnsmasq:
        port: 10054
        targetPort: 10054
      skydns:
        port: 10055
        targetPort: 10055
  kubeEtcd:
    enabled: false
    service:
      enabled: true
      port: 2381
      targetPort: 2381
    serviceMonitor:
      enabled: false
  kubeScheduler:
    enabled: false
    service:
      enabled: false
    serviceMonitor:
      enabled: false
  kubeProxy:
    enabled: false
    service:
      enabled: true
      port: 10249
      targetPort: 10249
    serviceMonitor:
      enabled: true
      https: false
  kubeStateMetrics:
    enabled: false
  kube-state-metrics:
    releaseLabel: true
    prometheus:
      monitor:
        enabled: false
    selfMonitor:
      enabled: false
  ## Controls whether the prometheus-node-exporter chart should be created.
  ## This block matches the configuration for the kube-prometheus-stack chart for compatibility.
  nodeExporter:
    enabled: false
  prometheus-node-exporter:
    prometheus:
      monitor:
        enabled: false